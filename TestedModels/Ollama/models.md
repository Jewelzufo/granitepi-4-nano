## Quantized Models (Unsloth)

Granite-4.0-H-350M is a lightweight instruct model finetuned from Granite-4.0-H-350M-Base using a combination of open-source instruction datasets with permissive license and internally collected synthetic datasets.

The following models were quantized for edge use cases.

*To install the model locally, open your shell and paste one of the following model Ollama commands to run the model.*

**Ollama Repo**: https://ollama.com/jewelzufo/unsloth_granite-4.0-h-350m-GGUF 

---

### IQ3_XXS (160mb)

```bash
ollama run jewelzufo/unsloth_granite-4.0-h-350m-GGUF:IQ3_XXS
```

### IQ4_XS (208mb)

```bash
ollama run jewelzufo/unsloth_granite-4.0-h-350m-GGUF:IQ4_XS
```
### IQ4_NL (216mb)

```bash
ollama run jewelzufo/unsloth_granite-4.0-h-350m-GGUF:IQ4_NL
```

### Q4_K_M (223mb)

To install from terminal:

```bash
ollama run jewelzufo/unsloth_granite-4.0-h-350m-GGUF
```

### Q5_K_XL (253mb)

```bash
ollama run jewelzufo/unsloth_granite-4.0-h-350m-GGUF:Q5_K_XL
```

### Q6_K (284mb)

```bash
ollama run jewelzufo/unsloth_granite-4.0-h-350m-GGUF:Q6_K
```

### Q6_K_XL (311mb)

```bash
ollama run jewelzufo/unsloth_granite-4.0-h-350m-GGUF:Q6_K_XL
```

---
